{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_graph(df) -> dict:\n",
    "    \"\"\"\n",
    "    returns a didct with keys = node key, and values = edges (node_id, edge weight) \n",
    "    \"\"\"\n",
    "    tree = {}\n",
    "    for _, row in df.iterrows():\n",
    "        parent = row['Parent']\n",
    "        child = row['Child']\n",
    "        weight = row['t']\n",
    "\n",
    "        # root node\n",
    "        if pd.isna(parent): \n",
    "            continue\n",
    "        # node already exists\n",
    "        elif parent in tree: \n",
    "            tree[parent].append((child, weight))\n",
    "        # node does not exists\n",
    "        else:\n",
    "            tree[parent] = [(child, weight)]\n",
    "    return tree\n",
    "\n",
    "\n",
    "def pd_z0():\n",
    "    return max(np.random.normal(alpha_0, np.sqrt(variance_0)), 1)\n",
    "\n",
    "\n",
    "def cpd(z, t):\n",
    "    mean = gamma_0 + (alpha * t) + (beta * z) + (gamma * t * z)\n",
    "    var = variance * t\n",
    "    return max(np.random.normal(mean, np.sqrt(var)), 1)\n",
    "\n",
    "\n",
    "def simulation(root: int, graph: dict, alpha0, variance0, alpha, beta, variance) -> dict:\n",
    "    \"\"\"\n",
    "    BFS\n",
    "    returns z value for all 407 nodes\n",
    "    \"\"\"\n",
    "    gene_lengths = {}\n",
    "    \n",
    "    z0 = max(np.random.normal(alpha0, np.sqrt(variance0)), 1)\n",
    "    queue = [(root, z0)]\n",
    "\n",
    "    while queue:\n",
    "        # handle the next element in queue\n",
    "        node, z = queue.pop(0)\n",
    "        \n",
    "        # set node in results in genelength z\n",
    "        gene_lengths[node] = z\n",
    "        \n",
    "        # get all children for the node\n",
    "        children = graph.get(node, [])\n",
    "\n",
    "        if not children:\n",
    "            continue\n",
    "        else:\n",
    "            # for all the children for this node calculate their z\n",
    "            # since we know it's a tree, only the parent can have influence\n",
    "            for child in children:\n",
    "                id, t = child\n",
    "                t = round(t, 3)\n",
    "                \n",
    "                # draw a sample\n",
    "                mean = (alpha * t) + (beta * z)\n",
    "                var = variance * t\n",
    "                \n",
    "                    \n",
    "                cpd_z = max(np.random.normal(mean, np.sqrt(var)), 1)\n",
    "                #print(f\"id:{id}, t:{t}, var:{var}, std:{np.sqrt(var)}, mean:{mean}, cpd:{cpd_z}\")\n",
    "                #if id == 205:\n",
    "                #    print(var)\n",
    "                #    print(mean)\n",
    "                #    print(cpd_z)\n",
    "                # append child to queue\n",
    "                queue.append((id, cpd_z))\n",
    "\n",
    "    return gene_lengths\n",
    "\n",
    "\n",
    "def n_simulations(n, root, graph, alpha0, variance0, alpha, beta, variance) -> tuple:\n",
    "    \"\"\"\n",
    "    Returns results for X=X1 ... X204 n times, and y=Z0 n times s\n",
    "    \"\"\"\n",
    "    X = np.empty((n, 204))\n",
    "    Z = np.empty((n, 203))\n",
    "    y = np.empty(n)\n",
    "    \n",
    "    for i in range(n):\n",
    "        results = simulation(root=root, graph=graph, alpha0=alpha0[i], variance0=variance0[i], alpha=alpha[i], beta=beta[i], variance=variance[i])\n",
    "        \n",
    "        # extract the first 204 values from the dictionary and add them to X as a row\n",
    "        row_X = [results[key] for key in range(1, 205)]\n",
    "        row_Z = [results[key] for key in range(205, 408)]\n",
    "        \n",
    "        X[i] = np.array(row_X)\n",
    "        Z[i] = np.array(row_Z)\n",
    "        \n",
    "        \n",
    "    return X, Z\n",
    "\n",
    "\n",
    "\n",
    "def dfs_paths_with_cpd(graph, start_node, z, path=None):\n",
    "    # returns all paths and the gene length at each node in the path\n",
    "    if path is None:\n",
    "        path = [(start_node, z)]\n",
    "\n",
    "    if start_node not in graph:\n",
    "        return [path]\n",
    "\n",
    "    paths = []\n",
    "    for child, t in graph[start_node]:\n",
    "        if child not in [node for node, _ in path]:\n",
    "            new_z = cpd(z, t)\n",
    "            child_paths = dfs_paths_with_cpd(graph, child, new_z, path + [(child, new_z)])\n",
    "            paths.extend(child_paths)\n",
    "\n",
    "    return paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "tree_data = pd.read_csv('data/tree.csv')\n",
    "genes_data = pd.read_csv('data/vert_genes.csv')\n",
    "\n",
    "# remove root node, since we already have reference to it from else where. unless issue with t?\n",
    "tree_data = tree_data[tree_data['Parent'].notna()]\n",
    "\n",
    "# convert parent col to ints\n",
    "tree_data['Parent'] = tree_data['Parent'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gamma_0 + (alpha * time) (beta * parent gene len) + (gamma * time * parent gene len)\n",
    "\n",
    "# Parameters\n",
    "# for Z_0\n",
    "size = 25000\n",
    "alpha0 = np.random.normal(50000, 50, size=size)\n",
    "variance0 = np.random.normal(5000, 10, size=size)\n",
    "\n",
    "# for Z_i and X_i\n",
    "alpha = np.random.normal(0, 0.5, size=size)\n",
    "beta = np.random.normal(1, 0.5, size=size)\n",
    "variance = np.random.normal(2500, 10, size=size)\n",
    "\n",
    "# Settings\n",
    "root = 407\n",
    "\n",
    "# create a dict graphe\n",
    "graph = create_graph(tree_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000,)\n"
     ]
    }
   ],
   "source": [
    "print(alpha0.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.9395675659 sec\n"
     ]
    }
   ],
   "source": [
    "# Create data\n",
    "t0 = time.time()\n",
    "\n",
    "X, Z = n_simulations(size, root, graph, alpha0, variance0, alpha, beta, variance)\n",
    "runtime = time.time() - t0\n",
    "print(f\"{runtime:.10f} sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 407)\n"
     ]
    }
   ],
   "source": [
    "V = np.concatenate((X,Z),axis=1)\n",
    "print(V.shape)\n",
    "#V = np.concatenate(X,Z,alpha0,variance0,alpha,beta,variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN. r2: 0.128, MSE: 0.216\n"
     ]
    }
   ],
   "source": [
    "# lin r\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "regAlpha = LinearRegression().fit(V, alpha)\n",
    "regBeta = LinearRegression().fit(V, beta)\n",
    "regSigma = LinearRegression().fit(V, variance)\n",
    "\n",
    "# Train results\n",
    "yt_pred = regAlpha.predict(V)\n",
    "train_r2 = regAlpha.score(V, alpha)\n",
    "train_mse = mean_squared_error(alpha, yt_pred)\n",
    "\n",
    "yt_pred1 = regBeta.predict(V)\n",
    "yt_pred2 = regSigma.predict(V)\n",
    "'''# Test results\n",
    "y_pred = reg.predict(X_test)\n",
    "test_r2 = r2_score(y_test, y_pred)\n",
    "test_mse = mean_squared_error(y_test, y_pred)'''\n",
    "\n",
    "print(f\"TRAIN. r2: {train_r2:.3f}, MSE: {train_mse:.3f}\")\n",
    "#print(f\"TEST. r2: {test_r2:.3f}, MSE: {test_mse:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.06701403  0.25286226  0.02780736 ... -0.20272192 -0.4784695\n",
      " -0.2102834 ]\n",
      "[ 0.0579253  -0.08552774  0.99559496 ... -0.73557041 -0.65097243\n",
      "  0.20786285]\n",
      "0.9969209878563571\n",
      "0.014035452510564261\n",
      "[0.0113959  0.01270408 0.00578217 ... 0.00500337 0.00187934 0.00593531]\n",
      "(array([2501.11470795, 2498.7509376 , 2500.94827719, ..., 2500.17988753,\n",
      "       2499.64498721, 2499.63709378]), array([2502.10826259, 2502.86992502, 2525.43214699, ..., 2520.95973919,\n",
      "       2484.29098515, 2504.15968984]))\n"
     ]
    }
   ],
   "source": [
    "print(yt_pred)\n",
    "print(alpha)\n",
    "\n",
    "print(regBeta.score(V,beta))\n",
    "print(regSigma.score(V,variance))\n",
    "print((yt_pred1-beta))\n",
    "print((yt_pred2,variance))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
