{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_graph(df) -> dict:\n",
    "    \"\"\"\n",
    "    returns a didct with keys = node key, and values = edges (node_id, edge weight) \n",
    "    \"\"\"\n",
    "    tree = {}\n",
    "    for _, row in df.iterrows():\n",
    "        parent = row['Parent']\n",
    "        child = row['Child']\n",
    "        weight = row['t']\n",
    "\n",
    "        # root node\n",
    "        if pd.isna(parent): \n",
    "            continue\n",
    "        # node already exists\n",
    "        elif parent in tree: \n",
    "            tree[parent].append((child, weight))\n",
    "        # node does not exists\n",
    "        else:\n",
    "            tree[parent] = [(child, weight)]\n",
    "    return tree\n",
    "\n",
    "\n",
    "def pd_z0():\n",
    "    return max(np.random.normal(alpha_0, np.sqrt(variance_0)), 1)\n",
    "\n",
    "\n",
    "def cpd(z, t):\n",
    "    mean = gamma_0 + (alpha * t) + (beta * z) + (gamma * t * z)\n",
    "    var = variance * t\n",
    "    return max(np.random.normal(mean, np.sqrt(var)), 1)\n",
    "\n",
    "\n",
    "def simulation(root: int, graph: dict, alpha0, variance0, alpha, beta, variance) -> dict:\n",
    "    \"\"\"\n",
    "    BFS\n",
    "    returns z value for all 407 nodes\n",
    "    \"\"\"\n",
    "    gene_lengths = {}\n",
    "    \n",
    "    z0 = max(np.random.normal(alpha0, np.sqrt(variance0)), 1)\n",
    "    queue = [(root, z0)]\n",
    "\n",
    "    while queue:\n",
    "        # handle the next element in queue\n",
    "        node, z = queue.pop(0)\n",
    "        \n",
    "        # set node in results in genelength z\n",
    "        gene_lengths[node] = z\n",
    "        \n",
    "        # get all children for the node\n",
    "        children = graph.get(node, [])\n",
    "\n",
    "        if not children:\n",
    "            continue\n",
    "        else:\n",
    "            # for all the children for this node calculate their z\n",
    "            # since we know it's a tree, only the parent can have influence\n",
    "            for child in children:\n",
    "                id, t = child\n",
    "                t = round(t, 3)\n",
    "                \n",
    "                # draw a sample\n",
    "                mean = (alpha * t) + (beta * z)\n",
    "                var = variance * t\n",
    "                \n",
    "                    \n",
    "                cpd_z = max(np.random.normal(mean, np.sqrt(var)), 1)\n",
    "                #print(f\"id:{id}, t:{t}, var:{var}, std:{np.sqrt(var)}, mean:{mean}, cpd:{cpd_z}\")\n",
    "                #if id == 205:\n",
    "                #    print(var)\n",
    "                #    print(mean)\n",
    "                #    print(cpd_z)\n",
    "                # append child to queue\n",
    "                queue.append((id, cpd_z))\n",
    "\n",
    "    return gene_lengths\n",
    "\n",
    "\n",
    "def n_simulations(n, root, graph, alpha0, variance0, alpha, beta, variance) -> tuple:\n",
    "    \"\"\"\n",
    "    Returns results for X=X1 ... X204 n times, and y=Z0 n times s\n",
    "    \"\"\"\n",
    "    X = np.empty((n, 204))\n",
    "    Z = np.empty((n, 203))\n",
    "    y = np.empty(n)\n",
    "    \n",
    "    for i in range(n):\n",
    "        results = simulation(root=root, graph=graph, alpha0=alpha0[i], variance0=variance0[i], alpha=alpha[i], beta=beta[i], variance=variance[i])\n",
    "        \n",
    "        # extract the first 204 values from the dictionary and add them to X as a row\n",
    "        row_X = [results[key] for key in range(1, 205)]\n",
    "        row_Z = [results[key] for key in range(205, 408)]\n",
    "        \n",
    "        X[i] = np.array(row_X)\n",
    "        Z[i] = np.array(row_Z)\n",
    "        \n",
    "        \n",
    "    return X, Z\n",
    "\n",
    "\n",
    "\n",
    "def dfs_paths_with_cpd(graph, start_node, z, path=None):\n",
    "    # returns all paths and the gene length at each node in the path\n",
    "    if path is None:\n",
    "        path = [(start_node, z)]\n",
    "\n",
    "    if start_node not in graph:\n",
    "        return [path]\n",
    "\n",
    "    paths = []\n",
    "    for child, t in graph[start_node]:\n",
    "        if child not in [node for node, _ in path]:\n",
    "            new_z = cpd(z, t)\n",
    "            child_paths = dfs_paths_with_cpd(graph, child, new_z, path + [(child, new_z)])\n",
    "            paths.extend(child_paths)\n",
    "\n",
    "    return paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "tree_data = pd.read_csv('data/tree.csv')\n",
    "genes_data = pd.read_csv('data/vert_genes.csv')\n",
    "\n",
    "# remove root node, since we already have reference to it from else where. unless issue with t?\n",
    "tree_data = tree_data[tree_data['Parent'].notna()]\n",
    "\n",
    "# convert parent col to ints\n",
    "tree_data['Parent'] = tree_data['Parent'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gamma_0 + (alpha * time) (beta * parent gene len) + (gamma * time * parent gene len)\n",
    "\n",
    "# Parameters\n",
    "# for Z_0\n",
    "size = 5000\n",
    "alpha0 = np.random.normal(50000, 50, size=size)\n",
    "variance0 = np.random.normal(5000, 10, size=size)\n",
    "\n",
    "# for Z_i and X_i\n",
    "alpha = np.random.normal(0, 0.5, size=size)\n",
    "beta = np.random.normal(3, 1, size=size)\n",
    "variance = np.random.normal(2500, 10, size=size)\n",
    "\n",
    "# Settings\n",
    "root = 407\n",
    "\n",
    "# create a dict graphe\n",
    "graph = create_graph(tree_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000,)\n",
      "[2507.95599739 2496.55227645 2494.44576974 ... 2512.51185711 2500.81716903\n",
      " 2502.6206323 ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2463.2606656378653, 2534.23100947955, 2500.0736038337445, 99.31103507879153)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(alpha0.shape)\n",
    "print(variance)\n",
    "np.min(variance),np.max(variance),np.mean(variance),np.var(variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.1944770813 sec\n"
     ]
    }
   ],
   "source": [
    "# Create data\n",
    "t0 = time.time()\n",
    "\n",
    "X, Z = n_simulations(size, root, graph, alpha0, variance0, alpha, beta, variance)\n",
    "runtime = time.time() - t0\n",
    "print(f\"{runtime:.10f} sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.14137273e+09 3.14137238e+09 1.70043061e+09 ... 3.67197424e+06\n",
      "  1.98754724e+06 5.00004684e+04]\n",
      " [3.56675415e+14 3.56675415e+14 1.01140763e+14 ... 3.40123002e+08\n",
      "  9.64471151e+07 5.01501600e+04]\n",
      " [1.45199501e+06 1.45168927e+06 1.20364187e+06 ... 1.84796413e+05\n",
      "  1.53144510e+05 4.99598036e+04]\n",
      " ...\n",
      " [7.18579284e+09 7.18579251e+09 3.71488886e+09 ... 5.06050771e+06\n",
      "  2.61607663e+06 4.99934032e+04]\n",
      " [2.83604683e+11 2.83604683e+11 1.19543499e+11 ... 2.11231344e+07\n",
      "  8.90383762e+06 5.00473885e+04]\n",
      " [7.01081420e+10 7.01081425e+10 3.19344953e+10 ... 1.22492379e+07\n",
      "  5.57958310e+06 4.99607803e+04]]\n"
     ]
    }
   ],
   "source": [
    "V = np.concatenate((X,Z),axis=1)\n",
    "print(V)\n",
    "#V = np.concatenate(X,Z,alpha0,variance0,alpha,beta,variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN. r2: 0.006, MSE: 0.250\n"
     ]
    }
   ],
   "source": [
    "# lin r\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "regAlpha = LinearRegression().fit(V, alpha)\n",
    "regBeta = LinearRegression().fit(V, beta)\n",
    "regSigma = LinearRegression().fit(V, variance)\n",
    "\n",
    "# Train results\n",
    "yt_pred = regAlpha.predict(V)\n",
    "train_r2 = regAlpha.score(V, alpha)\n",
    "train_mse = mean_squared_error(alpha, yt_pred)\n",
    "\n",
    "yt_pred1 = regBeta.predict(V)\n",
    "yt_pred2 = regSigma.predict(V)\n",
    "'''# Test results\n",
    "y_pred = reg.predict(X_test)\n",
    "test_r2 = r2_score(y_test, y_pred)\n",
    "test_mse = mean_squared_error(y_test, y_pred)'''\n",
    "\n",
    "print(f\"TRAIN. r2: {train_r2:.3f}, MSE: {train_mse:.3f}\")\n",
    "#print(f\"TEST. r2: {test_r2:.3f}, MSE: {test_mse:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.0043155  -0.01959604  0.01114266 ...  0.0026513  -0.00252054\n",
      " -0.00148036]\n",
      "[-0.0987917  -0.33863532 -0.49135237 ...  0.66877973  0.15390939\n",
      "  1.05729465]\n",
      "0.9054314112925632\n",
      "0.004374907558999719\n",
      "[-0.06076161 -0.19112354  0.23316474 ... -0.04686099  0.09508501\n",
      "  0.04230185]\n",
      "(array([2499.84524855, 2500.3631297 , 2500.20747693, ..., 2499.76313883,\n",
      "       2499.54257903, 2499.57524023]), array([2507.95599739, 2496.55227645, 2494.44576974, ..., 2512.51185711,\n",
      "       2500.81716903, 2502.6206323 ]))\n",
      "2486.3828413449646\n",
      "2463.2606656378653\n"
     ]
    }
   ],
   "source": [
    "print(yt_pred)\n",
    "print(alpha)\n",
    "\n",
    "print(regBeta.score(V,beta))\n",
    "print(regSigma.score(V,variance))\n",
    "print((yt_pred1-beta))\n",
    "print((yt_pred2,variance))\n",
    "print(np.min(yt_pred2))\n",
    "print(np.min(variance))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
