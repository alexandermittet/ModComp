{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_graph(df) -> dict:\n",
    "    \"\"\"\n",
    "    returns a didct with keys = node key, and values = edges (node_id, edge weight) \n",
    "    \"\"\"\n",
    "    tree = {}\n",
    "    for _, row in df.iterrows():\n",
    "        parent = row['Parent']\n",
    "        child = row['Child']\n",
    "        weight = row['t']\n",
    "\n",
    "        # root node\n",
    "        if pd.isna(parent): \n",
    "            continue\n",
    "        # node already exists\n",
    "        elif parent in tree: \n",
    "            tree[parent].append((child, weight))\n",
    "        # node does not exists\n",
    "        else:\n",
    "            tree[parent] = [(child, weight)]\n",
    "    return tree\n",
    "\n",
    "\n",
    "def pd_z0():\n",
    "    return max(np.random.normal(alpha_0, np.sqrt(variance_0)), 1)\n",
    "\n",
    "\n",
    "def cpd(z, t):\n",
    "    mean = gamma_0 + (alpha * t) + (beta * z) + (gamma * t * z)\n",
    "    var = variance * t\n",
    "    return max(np.random.normal(mean, np.sqrt(var)), 1)\n",
    "\n",
    "\n",
    "def simulation(root: int, graph: dict, alpha0, variance0, alpha, beta, variance) -> dict:\n",
    "    \"\"\"\n",
    "    BFS\n",
    "    returns z value for all 407 nodes\n",
    "    \"\"\"\n",
    "    gene_lengths = {}\n",
    "    \n",
    "    z0 = max(np.random.normal(alpha0, np.sqrt(variance0)), 1)\n",
    "    queue = [(root, z0)]\n",
    "\n",
    "    while queue:\n",
    "        # handle the next element in queue\n",
    "        node, z = queue.pop(0)\n",
    "        \n",
    "        # set node in results in genelength z\n",
    "        gene_lengths[node] = z\n",
    "        \n",
    "        # get all children for the node\n",
    "        children = graph.get(node, [])\n",
    "\n",
    "        if not children:\n",
    "            continue\n",
    "        else:\n",
    "            # for all the children for this node calculate their z\n",
    "            # since we know it's a tree, only the parent can have influence\n",
    "            for child in children:\n",
    "                id, t = child\n",
    "                t = round(t, 3)\n",
    "                \n",
    "                # draw a sample\n",
    "                mean = (alpha * t) + (beta * z)\n",
    "                var = variance * t\n",
    "                \n",
    "                    \n",
    "                cpd_z = max(np.random.normal(mean, np.sqrt(var)), 1)\n",
    "                #print(f\"id:{id}, t:{t}, var:{var}, std:{np.sqrt(var)}, mean:{mean}, cpd:{cpd_z}\")\n",
    "                #if id == 205:\n",
    "                #    print(var)\n",
    "                #    print(mean)\n",
    "                #    print(cpd_z)\n",
    "                # append child to queue\n",
    "                queue.append((id, cpd_z))\n",
    "\n",
    "    return gene_lengths\n",
    "\n",
    "\n",
    "def n_simulations(n, root, graph, alpha0, variance0, alpha, beta, variance) -> tuple:\n",
    "    \"\"\"\n",
    "    Returns results for X=X1 ... X204 n times, and y=Z0 n times s\n",
    "    \"\"\"\n",
    "    X = np.empty((n, 204))\n",
    "    Z = np.empty((n, 203))\n",
    "    y = np.empty(n)\n",
    "    \n",
    "    for i in range(n):\n",
    "        results = simulation(root=root, graph=graph, alpha0=alpha0[i], variance0=variance0[i], alpha=alpha[i], beta=beta[i], variance=variance[i])\n",
    "        \n",
    "        # extract the first 204 values from the dictionary and add them to X as a row\n",
    "        row_X = [results[key] for key in range(1, 205)]\n",
    "        row_Z = [results[key] for key in range(205, 408)]\n",
    "        \n",
    "        X[i] = np.array(row_X)\n",
    "        Z[i] = np.array(row_Z)\n",
    "        \n",
    "        \n",
    "    return X, Z\n",
    "\n",
    "\n",
    "\n",
    "def dfs_paths_with_cpd(graph, start_node, z, path=None):\n",
    "    # returns all paths and the gene length at each node in the path\n",
    "    if path is None:\n",
    "        path = [(start_node, z)]\n",
    "\n",
    "    if start_node not in graph:\n",
    "        return [path]\n",
    "\n",
    "    paths = []\n",
    "    for child, t in graph[start_node]:\n",
    "        if child not in [node for node, _ in path]:\n",
    "            new_z = cpd(z, t)\n",
    "            child_paths = dfs_paths_with_cpd(graph, child, new_z, path + [(child, new_z)])\n",
    "            paths.extend(child_paths)\n",
    "\n",
    "    return paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "tree_data = pd.read_csv('data/tree.csv')\n",
    "genes_data = pd.read_csv('data/vert_genes.csv')\n",
    "\n",
    "# remove root node, since we already have reference to it from else where. unless issue with t?\n",
    "tree_data = tree_data[tree_data['Parent'].notna()]\n",
    "\n",
    "# convert parent col to ints\n",
    "tree_data['Parent'] = tree_data['Parent'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gamma_0 + (alpha * time) (beta * parent gene len) + (gamma * time * parent gene len)\n",
    "\n",
    "# Parameters\n",
    "# for Z_0\n",
    "size = 5000\n",
    "alpha0 = np.random.normal(50000, 50, size=size)\n",
    "variance0 = np.random.normal(5000, 10, size=size)\n",
    "\n",
    "# for Z_i and X_i\n",
    "alpha = np.random.normal(0, 0.5, size=size)\n",
    "beta = np.random.normal(1, 0.5, size=size)\n",
    "variance = np.random.normal(2500, 10, size=size)\n",
    "\n",
    "# Settings\n",
    "root = 407\n",
    "\n",
    "# create a dict graphe\n",
    "graph = create_graph(tree_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000,)\n"
     ]
    }
   ],
   "source": [
    "print(alpha0.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.1088550091 sec\n"
     ]
    }
   ],
   "source": [
    "# Create data\n",
    "t0 = time.time()\n",
    "\n",
    "X, Z = n_simulations(size, root, graph, alpha0, variance0, alpha, beta, variance)\n",
    "runtime = time.time() - t0\n",
    "print(f\"{runtime:.10f} sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6.17393885e+03 6.19982591e+03 6.85236487e+03 ... 2.21817237e+04\n",
      "  2.49987600e+04 4.99785999e+04]\n",
      " [1.66617795e+04 1.66808852e+04 1.75929181e+04 ... 3.28565512e+04\n",
      "  3.48009465e+04 5.01124008e+04]\n",
      " [1.00000000e+00 2.19569460e+02 1.00000000e+00 ... 5.93190327e+02\n",
      "  1.06469957e+03 5.00457284e+04]\n",
      " ...\n",
      " [1.39854334e+07 1.39854487e+07 1.02275579e+07 ... 4.49421394e+05\n",
      "  3.28717607e+05 5.00245716e+04]\n",
      " [6.95480024e+04 6.97026027e+04 6.80635366e+04 ... 5.71896377e+04\n",
      "  5.60733356e+04 4.99743051e+04]\n",
      " [1.63185145e+07 1.63187518e+07 1.18308934e+07 ... 4.75423467e+05\n",
      "  3.44609483e+05 5.00207783e+04]]\n"
     ]
    }
   ],
   "source": [
    "V = np.concatenate((X,Z),axis=1)\n",
    "print(V)\n",
    "#V = np.concatenate(X,Z,alpha0,variance0,alpha,beta,variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN. r2: 0.192, MSE: 0.207\n"
     ]
    }
   ],
   "source": [
    "# lin r\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "regAlpha = LinearRegression().fit(V, alpha)\n",
    "regBeta = LinearRegression().fit(V, beta)\n",
    "regSigma = LinearRegression().fit(V, variance)\n",
    "\n",
    "# Train results\n",
    "yt_pred = regAlpha.predict(V)\n",
    "train_r2 = regAlpha.score(V, alpha)\n",
    "train_mse = mean_squared_error(alpha, yt_pred)\n",
    "\n",
    "yt_pred1 = regBeta.predict(V)\n",
    "yt_pred2 = regSigma.predict(V)\n",
    "'''# Test results\n",
    "y_pred = reg.predict(X_test)\n",
    "test_r2 = r2_score(y_test, y_pred)\n",
    "test_mse = mean_squared_error(y_test, y_pred)'''\n",
    "\n",
    "print(f\"TRAIN. r2: {train_r2:.3f}, MSE: {train_mse:.3f}\")\n",
    "#print(f\"TEST. r2: {test_r2:.3f}, MSE: {test_mse:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2.44198439e-01 -3.85595290e-04 -2.67656462e-02 ... -4.62825492e-01\n",
      "  2.26596117e-01  8.65992910e-02]\n",
      "[-0.09824802  0.29408099  0.14650702 ...  0.00471274 -0.42163605\n",
      " -0.85698018]\n",
      "0.9963042726961431\n",
      "0.09064019245570931\n",
      "[ 0.0090476   0.0103847  -0.0002175  ... -0.00441527 -0.00641005\n",
      "  0.00483902]\n",
      "(array([2500.963598  , 2498.30052594, 2498.7826872 , ..., 2497.88379795,\n",
      "       2502.1648148 , 2499.51122527]), array([2505.50460715, 2503.70686183, 2497.91219724, ..., 2490.68477301,\n",
      "       2505.96769832, 2506.51934738]))\n",
      "2478.399855960714\n",
      "2460.166710010255\n"
     ]
    }
   ],
   "source": [
    "print(yt_pred)\n",
    "print(alpha)\n",
    "\n",
    "print(regBeta.score(V,beta))\n",
    "print(regSigma.score(V,variance))\n",
    "print((yt_pred1-beta))\n",
    "print((yt_pred2,variance))\n",
    "print(np.min(yt_pred2))\n",
    "print(np.min(variance))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
